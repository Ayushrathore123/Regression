{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e9d18d3",
   "metadata": {},
   "source": [
    "Q1. What is Lasso Regression, and how does it differ from other regression techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f064ac5a",
   "metadata": {},
   "source": [
    "Lasso Regression is a linear regression technique that adds a penalty term (L1 regularization) to the ordinary least squares regression. It differs from other regression techniques by promoting sparsity and performing feature selection, as it can shrink the coefficients of less important variables to exactly zero, effectively removing them from the model. Lasso Regression is useful when dealing with high-dimensional data and when there is a belief that only a subset of features is truly relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1307e2e3",
   "metadata": {},
   "source": [
    "Q2. What is the main advantage of using Lasso Regression in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e418508f",
   "metadata": {},
   "source": [
    "The main advantage of using Lasso Regression in feature selection is its ability to automatically select and exclude irrelevant or less important features by shrinking their coefficients to zero. This helps in simplifying the model, improving interpretability, and reducing overfitting by focusing on the most influential predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db16c2b6",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the coefficients of a Lasso Regression model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b54b4ef",
   "metadata": {},
   "source": [
    "In Lasso Regression, the coefficients can be interpreted as the impact of each predictor variable on the target variable. The magnitude of the coefficients indicates the strength of the relationship, with larger coefficients representing more significant effects, while zero coefficients indicate that the corresponding predictors are excluded from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a306dbc7",
   "metadata": {},
   "source": [
    "Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "model's performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d828cf67",
   "metadata": {},
   "source": [
    "\n",
    "The main tuning parameter in Lasso Regression is the regularization parameter (alpha). By adjusting the value of alpha, you can control the strength of the regularization and the amount of sparsity in the model. A larger alpha increases the regularization, leading to more coefficients being shrunk to zero, resulting in a sparser model with potentially better feature selection but potentially sacrificing some predictive performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7986b85a",
   "metadata": {},
   "source": [
    "Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b94864",
   "metadata": {},
   "source": [
    "Lasso Regression is primarily designed for linear regression problems. However, it can be extended to handle non-linear regression by incorporating non-linear transformations of the predictor variables, such as polynomial terms or interaction terms. By including these non-linear terms as additional features, Lasso Regression can capture and model the non-linear relationships between the predictors and the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29a3f53",
   "metadata": {},
   "source": [
    "Q6. What is the difference between Ridge Regression and Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fe4656",
   "metadata": {},
   "source": [
    "The main difference between Ridge Regression and Lasso Regression lies in the type of regularization used. Ridge Regression uses L2 regularization, which shrinks the coefficients towards zero but does not eliminate any predictors entirely, while Lasso Regression uses L1 regularization, which not only shrinks coefficients but also performs feature selection by setting some coefficients to exactly zero, effectively excluding those predictors from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd970002",
   "metadata": {},
   "source": [
    "Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e521b7",
   "metadata": {},
   "source": [
    "Yes, Lasso Regression can handle multicollinearity in the input features to some extent. The L1 regularization in Lasso Regression encourages sparsity and can automatically select one of the highly correlated variables while shrinking the coefficients of the others towards zero, effectively addressing multicollinearity and promoting a more stable model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843fbb09",
   "metadata": {},
   "source": [
    "Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5db49b7",
   "metadata": {},
   "source": [
    "The optimal value of the regularization parameter (lambda) in Lasso Regression is typically chosen using techniques like cross-validation. Different values of lambda are tested, and the one that yields the best model performance, such as the lowest cross-validation error or highest cross-validation accuracy, is selected as the optimal value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aac962",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
